{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "import autogen\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import logging\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set your API key\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=\"\"\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key)\n",
    "\n",
    "# Configure logging at the start of your script\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow description\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to optimize the colaboration between AI and Developer during Spring Deelopment followng Devonfw guidelines.\n",
    "\n",
    "Given a Database Schema, we want a system to be concise, while accelerating the development process. Therefore we need the system to be as autonomous as possible, while being applicable to a large number of project. Thus the system needs a high amount of flexibility. As first experiments demonstrated, the state of LLMs is not advanced enough to autonomously make useful design decisions. Thus a high amount of flexibility must be met with human oversight. \n",
    "This new workflow, focusses on providing one \"meta-workflow\" with multiple \"increment workflows\" induced. The system will autonomously create files, write code and perform a review, but always asks for human feedback, or input for design decisions before performing a task. \n",
    "\n",
    "To make sure the communication between human and AI stays minimal, a global variable store is needed, that can be accessed by an agent in order to not ask questions repeatedly.\n",
    "\n",
    "## 0. Meta Workflow\n",
    "    1. Start the component workflow\n",
    "    2. Repeat untill all components are implemented\n",
    "## 1. Component workflow\n",
    "The DB_schema.md file is structured into Business components. One business comnonent will be implemented by implementing all Entities inside the component.\n",
    "\n",
    "    1. Determine the location of the business component\n",
    "    2. Build the required blueprint structure following devon guidelines\n",
    "    3. Start the Entity workflow\n",
    "    4. Repeat 3. until all Entites are implemented\n",
    "    5. Terminate\n",
    "\n",
    "## 2. Entity Workflow\n",
    "One entity consists of multiple parts and needs to  be organized into multiple files. \n",
    "\n",
    "    1. Determine location of Entity file\n",
    "    2. Create Entity file\n",
    "    3. Implement necessary library imports\n",
    "    4. Deduce necessary imports from the relationships defined in db_schema.md\n",
    "    5. Create DTO? Where?\n",
    "    6. Does the DB_Schema suggest any additional common files like enums etc.?\n",
    "    7. Review the implementation\n",
    "       1. View list of generated files for the entity\n",
    "       2. For every file, compare with requirements and devon guidelines\n",
    "       3. Fill out Review.md file\n",
    "       4. If problems found, pass on to coder\n",
    "       5. Repeat Review workflow until no problems in review\n",
    "\n",
    "## 3. Repository workflow\n",
    "When the Entity files are implemented we ned a repository. The needed queries can by looking at the Db_schema (unuderstand the usage of the entity) and also the implementation.\n",
    "\n",
    "    1. View requirements and implementation\n",
    "    2. Suggest queries to human and ask for feedback\n",
    "    3. implement repository\n",
    "\n",
    "## 4. Test Entity implementation\n",
    "The complete entity implementation needs to be tested. Thus we need information about all files that have been created for the entity and all functionalities.\n",
    "\n",
    "    1. Gather information on\n",
    "       1. Generated files\n",
    "       2. Implemented relationships\n",
    "    2. Generate testfile\n",
    "    3. Implement testcases\n",
    "    4. Execute Tests\n",
    "    5. Review Results and Generate report\n",
    "    6. If not all tests successfull, send report to coder and repeat until all tests succesfull\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed Agents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicriptions of the agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta Agent\n",
    "#### Component Agent\n",
    "#### Entity Coder Agent\n",
    "- Global variables:\n",
    "  - Filepath to dataaccess layer\n",
    "- Tools:\n",
    "  - list_dir\n",
    "  - Read_file\n",
    "  - Write file\n",
    "  - Modify file?\n",
    "  - StoreGlobal?\n",
    "  - Ask_human\n",
    "\n",
    "#### Random Coder Agent\n",
    "\n",
    "#### DTO and Common Agent\n",
    "- Global variables:\n",
    "  - Dtos creation True, False, Ask\n",
    "  - path to dataaccess layer/common folder\n",
    "- Tools:\n",
    "  - read_file\n",
    "  - write_file\n",
    "  \n",
    "#### Review Agent\n",
    "- Global variables:\n",
    "\n",
    "- Tools:\n",
    "  - read file\n",
    "\n",
    "#### Code fix Agent\n",
    "- Global variables:\n",
    "  - Filepath to dataaccess layer\n",
    "\n",
    "- Tools:\n",
    "  - read_file\n",
    "  - write_file / modify_file\n",
    "  - \n",
    "  \n",
    "#### Repository Agent\n",
    "- Global variables:\n",
    "  - Path to dataaccess layer\n",
    "\n",
    "- Tools:\n",
    "  - read_file\n",
    "  - write_file\n",
    "  - ask_human\n",
    "  \n",
    "#### Test Agent\n",
    "  - Global variables:\n",
    "    - what has been created\n",
    "\n",
    "  - Tools:\n",
    "    - Read file\n",
    "    - Write file\n",
    "    - run_test\n",
    "    - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ReAct\n",
    "2. Thought instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_question = f\"\"\"\n",
    "According to the review the agent suggests to reimplement the file.\n",
    "Should I proceed with the reimplementation? If yes press enter, if no, type anything to stop the review loop\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_message_entity_coder = \"\"\"\n",
    "You are an experienced SpringBoot developer adhering to devonfw guidelines. You write and insert code into an existing [Entity].java file, when given the required information.\n",
    "\n",
    "Design guidelines you must follow:\n",
    "Design a JPA/Hibernate Java entity with @Entity, and optionally @Table for naming (TableName Convention: always use singular.). Use @Column for mapping attributes to columns; ensure a no-argument constructor,\n",
    "non-final classes/methods for Hibernate. Utilize standard Java types, custom types via AttributeConverter or @Embeddable. For Enums, use @Enumerated(EnumType.STRING);\n",
    "large objects with @Lob, considering streaming for BLOBs. Handle dates with @Temporal. Define relationships with @ManyToOne, @OneToMany, @ManyToMany (lazy by default), \n",
    "@OneToOne (set to lazy), avoid bidirectional complexities, use Sets for collections, and Long with @GeneratedValue for primary keys. Implement embeddables with @Embeddable, \n",
    "choose @Inheritance strategy, typically SINGLE_TABLE. Entities should be simple, database-structure focused, avoiding business logic. \n",
    "Import Lombok for auto-generating getters/setters and annotate the Columns accordingly.\n",
    "Use  import jakarta.persistence.* to efficiently import the library!\n",
    "\n",
    "You always adhere to the following steps:\n",
    "1. Think about the requirements and implementation guidelines given to you\n",
    "2. Implement the Entity in the existing [Entity].java file directly using the respective function call. \n",
    "Implement the Entity EXACTLY as described in the requirements, do NOT change any names of attributes or relationships.\t\n",
    "3. When you´re done end the session with \"TERMINATE\".\n",
    "When there are no further instructions write \"TERMINATE\"\n",
    "\"\"\"\n",
    "\n",
    "system_message_repository_coder = \"\"\"\n",
    "\n",
    "\n",
    "You are an experienced SpringBoot developer adhering to devonfw guidelines. You write and insert code into an existing [Entity]Repository.java file, when given the required information.\n",
    "The repository should extend JpaRepository.\n",
    "Make sure to import the entity and the JpaRepository from the correct package.\n",
    "\n",
    "When you´re done end the session with \"TERMINATE\".\n",
    "When there are no further instructions write \"TERMINATE\".\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_message_coder = \"\"\"\n",
    "You are a SpringBoot developer following devon guidelines. You are tasked with implementing a Java file.\n",
    "You are given the description for the files, the filenames, the path to the files and the package name. Use the respective function to implement those files accordingly.\n",
    "Make sure to follow Java naming Conventions and the devonfw guidelines.\n",
    "\n",
    "When you´re done end the session with \"TERMINATE\".\n",
    "When there are no further instructions write \"TERMINATE\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_message_redo_coder = \"\"\"\n",
    "You are a SpringBoot developer following devon guidelines. You are tasked with redoing the implementation of a file in order to make it suit the requirements and guidelines.\n",
    "\n",
    "When you´re done end the session with \"TERMINATE\".\n",
    "When there are no further instructions write \"TERMINATE\".\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_project_name = [x for x in os.listdir(\"..\") if x != \"Autogen\"][0]\n",
    "\n",
    "# append the name of the SpringBoot project to the index_path\n",
    "spring_project_path = os.path.join(\"..\", spring_project_name)\n",
    "\n",
    "model = \"gpt-4-1106-preview\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"configurations.json\",\n",
    "    file_location=\"./\",\n",
    "    filter_dict={\n",
    "        \"model\": [model]\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": 42,\n",
    "    \"timeout\": 120,\n",
    "    \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "\n",
    "entity_coder= AssistantAgent(name =\"entity_coder\",\n",
    "                                    system_message=system_message_entity_coder,\n",
    "                                    human_input_mode=\"ALWAYS\",\n",
    "                                     llm_config={\"config_list\": config_list})\n",
    "entity_proxy = UserProxyAgent(name=\"entity_proxy\",\n",
    "                            system_message=\"Terminate when agent says TERMINATE\",\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                             code_execution_config={\"work_dir\": \"codingg\", \"use_docker\": False}) # IMPORTANT: set to True to run code in docker, recommended\n",
    "\n",
    "repo_coder= AssistantAgent(name =\"repo_coder\",\n",
    "                                    system_message=system_message_repository_coder,\n",
    "                                    human_input_mode=\"ALWAYS\",\n",
    "                                     llm_config={\"config_list\": config_list})\n",
    "\n",
    "repo_proxy = UserProxyAgent(name=\"repo_proxy\",\n",
    "                            system_message=\"Terminate when agent says TERMINATE\",\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                             code_execution_config={\"work_dir\": \"codingg\", \"use_docker\": False}) # IMPORTANT: set to True to run code in docker, recommended\n",
    "\n",
    "coder= AssistantAgent(name =\"coder\",\n",
    "                        system_message=system_message_coder,\n",
    "                        human_input_mode=\"ALWAYS\",\n",
    "                            llm_config={\"config_list\": config_list})\n",
    "\n",
    "coder_proxy = UserProxyAgent(name=\"coder_proxy\",\n",
    "                            system_message=\"Terminate when agent says TERMINATE\",\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                             code_execution_config={\"work_dir\": \"codingg\", \"use_docker\": False}) # IMPORTANT: set to True to run code in docker, recommended\n",
    "\n",
    "redo_coder= AssistantAgent(name =\"redo_coder\",\n",
    "                                    system_message=system_message_redo_coder,\n",
    "                                    human_input_mode=\"ALWAYS\",\n",
    "                                     llm_config={\"config_list\": config_list})\n",
    "redo_proxy = UserProxyAgent(name=\"redo_proxy\",\n",
    "                            system_message=\"Terminate when agent says TERMINATE\",\n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "                             code_execution_config={\"work_dir\": \"codingg\", \"use_docker\": False}) # IMPORTANT: set to True to run code in docker, recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways of launching agents\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Static agent: Follows strict procedure --> Static launch message, static system message, no global variables\n",
    "   \n",
    "    2. Dynamic Agent: Needs varying information depending on task. Information can be provided by:\n",
    "\n",
    "       1. Dynamic System message\n",
    "       2. Dynamic Chat initiation\n",
    "       3. Global variables\n",
    "\n",
    "    3. Hyper Dynamic Agent (concept): Same as dynamic, but also has dynamic access to functions\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Follow devon standards (how to induce them?)\n",
    "- Follow user instructions\n",
    "- Being able to roll back to a state if an error is detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. List_dir\n",
    "2. read_file\n",
    "3. write_file\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_directories() -> Annotated[str, \"outputs file tree like tree command in cmd\"]:\n",
    "\n",
    "    path = spring_project_path\n",
    "    directory_structure = \"\"\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Filter out hidden directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        level = root.replace(path, '').count(os.sep)\n",
    "        indent = ' ' * 4 * level\n",
    "        directory_structure += '{}{}/\\n'.format(indent, os.path.basename(root))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            directory_structure += '{}{}\\n'.format(subindent, f)\n",
    "    \n",
    "    return directory_structure\n",
    "\n",
    "def read_file(file_path: Annotated[str, \"Relative path starting from the springboot directory to file location\"]) -> str:\n",
    "    \"\"\"\n",
    "    Extratcts all Columns, relationships and keys that are relevant for the entity out of the db_Schema.md file.\n",
    "    Then it navigates to the correct java file and implements all the methods that are needed for the entity inside the existing file\n",
    "\n",
    "    Parameters:\n",
    "        entity_name (str): The name of the entity.\n",
    "        location_of_file (str): The location of the file where the entity is implemented.\n",
    "    \"\"\"\n",
    "\n",
    "    # helper to return the initial path provided by the llm\n",
    "    initial_file_path=file_path\n",
    "\n",
    "    # normalize the path changing forward slashes to backslashes\n",
    "    file_path = file_path.replace(\"/\", \"\\\\\")\n",
    "\n",
    "    # check if first folder of the path is the last of the spring project folder before joining them\n",
    "    if file_path.split(\"\\\\\")[0] == spring_project_path.split(\"\\\\\")[-1]:\n",
    "        file_path = file_path.split(\"\\\\\", 1)[1]\n",
    "\n",
    "    # join the path of the spring project with the location of the file\n",
    "    file_path = os.path.join(spring_project_path, file_path)\n",
    "\n",
    "    # possible error handling for wrong path\n",
    "    if not os.path.exists(file_path):\n",
    "        tree = list_directories()\n",
    "        return f\"\"\"The file does not exist at {initial_file_path}. This is our project structure: {tree} Please check the path and try again\"\"\"\n",
    "    \n",
    "    else:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "    return content\n",
    "\n",
    "@coder_proxy.register_for_execution()\n",
    "@redo_proxy.register_for_execution()\n",
    "@entity_proxy.register_for_execution()\n",
    "@repo_proxy.register_for_execution()\n",
    "@coder.register_for_llm(description=\"writes code or text to a file at a specified path\")\n",
    "@redo_coder.register_for_llm(description=\"writes code or text to a file at a specified path\")\n",
    "@entity_coder.register_for_llm(description=\"writes code or text to a file at a specified path\")\n",
    "@repo_coder.register_for_llm(description=\"writes code or text to a file at a specified path\")\n",
    "def write_file(file_path: Annotated[str, \"File path\"], content: Annotated[str, \"Content to be written to the file\"]) -> Annotated[str, \"Success message\"]:\n",
    "    \"\"\"\n",
    "    Writes the content to the file at the given file path.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the file where the content should be written to.\n",
    "        content (str): The content that should be written to the file.\n",
    "    \"\"\"\n",
    "    initial_file_path=file_path\n",
    "\n",
    "    # normalize the path changing forward slashes to backslashes\n",
    "    file_path = file_path.replace(\"/\", \"\\\\\")\n",
    "\n",
    "    # check if first folder of the path is the last of the spring project folder before joining them\n",
    "    if file_path.split(\"\\\\\")[0] == spring_project_path.split(\"\\\\\")[-1]:\n",
    "        file_path = file_path.split(\"\\\\\", 1)[1]\n",
    "\n",
    "    # join the path of the spring project with the location of the file\n",
    "    file_path = os.path.join(spring_project_path, file_path)\n",
    "\n",
    "    # cut last part of the path to get the directory path\n",
    "    directory_path = os.path.dirname(file_path)\n",
    "    \n",
    "\n",
    "    # possible error handling for wrong path\n",
    "    if not os.path.exists(directory_path):\n",
    "        tree = list_directories()\n",
    "        return f\"\"\"The file does not exist at {initial_file_path}. This is our project structure: {tree} Please check the path and try again\"\"\"\n",
    "    \n",
    "    else:\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    return f\"Content successfully written to {file_path}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special purpose action functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ask_human\n",
    "2. get_component_name\n",
    "3. get_entity_name\n",
    "4. get_entity_requirements\n",
    "5. create_component_structure\n",
    "6. document_entity\n",
    "7. mark_entity_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mark_component_done()-> Annotated[str, \"Success message when component is marked as done\"]:\n",
    "    \"\"\"\n",
    "    Checks for the next unchecked component in the db_schema.md file and checks the next one as done.\n",
    "    Returns a message indicating all components are checked if no unchecked component is found.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Flag to indicate whether a component has been marked as done\n",
    "    component_marked = False\n",
    "\n",
    "    # Iterate over each line in the file\n",
    "    for i, line in enumerate(lines):\n",
    "        # Check if a new unchecked component section starts\n",
    "        if line.startswith(\"# [ ] Component:\") and not component_marked:\n",
    "            # Mark the component as done by changing the start of the line\n",
    "            lines[i] = line.replace(\"[ ]\", \"[x]\")\n",
    "            component_marked = True\n",
    "            break  # Exit the loop after marking a component\n",
    "\n",
    "    # Write the updated lines back to the file\n",
    "    with open(\"./db_schema.md\", 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return \"Component has been marked as done. TERMINATE\"\n",
    "\n",
    "def mark_next_entity_done()-> Annotated[str, \"Success message when entity is marked as done\"]:\n",
    "\n",
    "    \"\"\"\n",
    "    Checks for the next unchecked entity in the db_schema.md file and checks the next one as done.\n",
    "    Returns a message indicating all entities are checked if no unchecked entity is found.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Flag to indicate whether an entity has been marked as done\n",
    "    entity_marked = False\n",
    "\n",
    "    # Iterate over each line in the file\n",
    "    for i, line in enumerate(lines):\n",
    "        # Check if a new unchecked entity section starts\n",
    "        if line.startswith(\"## [ ] Entity:\") and not entity_marked:\n",
    "            # Mark the entity as done by changing the start of the line\n",
    "            lines[i] = line.replace(\"[ ]\", \"[x]\")\n",
    "            entity_marked = True\n",
    "            break  # Exit the loop after marking an entity\n",
    "\n",
    "    # Write the updated lines back to the file\n",
    "    with open(\"./db_schema.md\", 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return \"Entity has been marked as done. TERMINATE\"\n",
    "\n",
    "def create_component_structure(component_base_path:Annotated[str, \"Relative path from Spring project to where component should be created\"])->str:\n",
    "    \"\"\"\n",
    "    Creates a blueprint for a Spring component, handling deeper base paths.\n",
    "    \n",
    "    Parameters:\n",
    "        component_base_path (str): The path inside the existing SpringBoot project, where the component should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    # read the db schema file and to get then next component\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        db_schema = file.read()\n",
    "\n",
    "\n",
    "    # Find the first component name using a regular expression\n",
    "    component_pattern = re.compile(r'# \\[ \\] Component: (\\w+)')\n",
    "    component_match = component_pattern.search(db_schema)\n",
    "\n",
    "    if not component_match:\n",
    "        return \"All components implemented. TERMINATE\"\n",
    "\n",
    "\n",
    "    ### get list of all entities within the component, so stop the search when the next component starts\n",
    "    \n",
    "    # Extract the portion of the schema for the current component\n",
    "    start_index = component_match.end()\n",
    "    next_component_match = component_pattern.search(db_schema, start_index)\n",
    "    if next_component_match:\n",
    "        component_schema = db_schema[start_index:next_component_match.start()]\n",
    "    else:\n",
    "        component_schema = db_schema[start_index:]\n",
    "\n",
    "    # Find all entity names within the component\n",
    "    entity_pattern = re.compile(r'## \\[ \\] Entity: (\\w+)')\n",
    "    entities = entity_pattern.findall(component_schema)\n",
    "\n",
    "    ### Create the component folder structure    \n",
    "    component_base_path = component_base_path.replace(\"/\", \"\\\\\")\n",
    "    # check if first folder of the path is the last of the spring project folder before joining them\n",
    "    if component_base_path.split(\"\\\\\")[0] == spring_project_path.split(\"\\\\\")[-1]:\n",
    "        component_base_path = component_base_path.split(\"\\\\\", 1)[1]\n",
    "\n",
    "    # join the path of the spring project with the location of the file\n",
    "    component_base_path = os.path.join(spring_project_path, component_base_path)\n",
    "\n",
    "    # Check if the path exists\n",
    "    if not os.path.exists(component_base_path):\n",
    "        return\tf\"The path {component_base_path} does not exist. Please check the path and try again.\"\n",
    "    \n",
    "    component_name = component_match.group(1)\n",
    "\n",
    "    # Normalize the base path by replacing backslashes with forward slashes and join with entity name\n",
    "    component_path = os.path.join(component_base_path.replace('/', '\\\\'), component_name.lower())\n",
    "\n",
    "    os.makedirs(component_path, exist_ok=True)\n",
    "\n",
    "    # create the subfolders common, domain, logic, service\n",
    "    subfolders = ['common', 'dataaccess', 'logic', 'service']\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(component_path, subfolder)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "    # create and repository folder inside domain and dto folder inside common\n",
    "    dataaccess_path = os.path.join(component_path, 'dataaccess')\n",
    "    repository_path = os.path.join(component_path, 'dataaccess', 'repository')\n",
    "    dto_path = os.path.join(component_path, 'common', 'to')\n",
    "    os.makedirs(dataaccess_path, exist_ok=True)\n",
    "    os.makedirs(repository_path, exist_ok=True)\n",
    "    os.makedirs(dto_path, exist_ok=True)\n",
    "\n",
    "    # create the [Entity].java and [Entity]Repository.java files inside domain/model and domain/repository\n",
    "    for entity in entities:\n",
    "\n",
    "        # make sure the entity name starts with an uppercase letter\n",
    "        entity = entity.capitalize()\n",
    "        with open(os.path.join(dataaccess_path, f'{entity}.java'), 'w') as f:\n",
    "            pass\n",
    "        with open(os.path.join(repository_path, f'{entity}Repository.java'), 'w') as f:\n",
    "            pass\n",
    "\n",
    "        # create Dto.java file inside common/to\n",
    "        with open(os.path.join(dto_path, f'{entity}Dto.java'), 'w') as f:\n",
    "            pass\n",
    "    # create component.java file inside logic\n",
    "    with open(os.path.join(component_path, 'logic', f'{component_name.capitalize()}.java'), 'w') as f:\n",
    "        pass\n",
    "\n",
    "    return f\"\"\"The folders and files for {component_name} have been created. The [Entity].java files are located in {component_path}/dataaccess.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_name()-> Annotated[str, \"Name of the next entity to be implemented\"]:\n",
    "\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        db_schema = file.read()\n",
    "\n",
    "    # Find the first component name using a regular expression\n",
    "    component_pattern = re.compile(r'# \\[ \\] Component: (\\w+)')\n",
    "    component_match = component_pattern.search(db_schema)\n",
    "    \n",
    "    # Extract the portion of the schema for the current component\n",
    "    start_index = component_match.end()\n",
    "    next_component_match = component_pattern.search(db_schema, start_index)\n",
    "    if next_component_match:\n",
    "        component_schema = db_schema[start_index:next_component_match.start()]\n",
    "    else:\n",
    "        component_schema = db_schema[start_index:]\n",
    "\n",
    "    # Find next unchecked within the component\n",
    "    entity_pattern = re.compile(r'## \\[ \\] Entity: (\\w+)')\n",
    "\n",
    "    # only get next unchecked Entity\n",
    "    next_entity = entity_pattern.search(component_schema).group(1)\n",
    "    \n",
    "    if not next_entity:\n",
    "        # mark the component done by changing the first component_match to [x]\n",
    "        db_schema = db_schema.replace(component_match.group(0), component_match.group(0).replace(\"[ ]\", \"[x]\"), 1)\n",
    "        return \"All entities are implemented, component has been marked as done. TERMINATE\"\n",
    "\n",
    "    # Return the first match if any, else None\n",
    "    return next_entity \n",
    "\n",
    "def get_entity_requirements() -> Annotated[str, \"Requirements for current the entity\"]:\n",
    "    # Open and read the markdown file\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        db_schema = file.read()\n",
    "\n",
    "    # Pattern to identify the start of the first unchecked component\n",
    "    component_pattern = re.compile(r'# \\[ \\] Component: \\w+')\n",
    "    component_start_match = component_pattern.search(db_schema)\n",
    "    \n",
    "    if not component_start_match:\n",
    "        return \"All components are implemented. TERMINATE\"\n",
    "    \n",
    "    # Narrow down the search to start from the first unchecked component\n",
    "    db_schema_from_first_component = db_schema[component_start_match.start():]\n",
    "\n",
    "    # Pattern to find the first unchecked entity after the first unchecked component\n",
    "    # Ensuring it only captures up to the start of the next entity or the end of the component\n",
    "    entity_pattern = re.compile(r'## \\[ \\] Entity: (\\w+)(.*?)(?=## \\[ \\]|# \\[ \\]|$)', re.DOTALL)\n",
    "    entity_match = entity_pattern.search(db_schema_from_first_component)\n",
    "\n",
    "    if entity_match:\n",
    "        entity_name = entity_match.group(1)\n",
    "        details = entity_match.group(2).strip()\n",
    "        full_text = f\"Entity name: {entity_name}\\nDetails: {details}\"\n",
    "        return full_text\n",
    "    else:\n",
    "        return \"No unchecked entities found. TERMINATE\"\n",
    "\n",
    "def get_component_name() -> Annotated[str, \"Name of the next component to be implemented\"]:\n",
    "    \"\"\"\n",
    "    Extracts the name of the next component that needs to be implemented from the db_schema.md file.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the next component that needs to be implemented.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"./db_schema.md\", 'r') as file:\n",
    "        db_schema = file.read()\n",
    "\n",
    "    # Find the first component name using a regular expression\n",
    "    component_pattern = re.compile(r'# \\[ \\] Component: (\\w+)')\n",
    "    component_match = component_pattern.search(db_schema)\n",
    "    \n",
    "    # Return the first match if any, else None\n",
    "    return component_match.group(1).lower() if component_match else \"All components are implemented. TERMINATE\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_files_message():\n",
    "\n",
    "    entity_req = get_entity_requirements()\n",
    "    entity_name = get_entity_name()\n",
    "\n",
    "    system_message = f\"\"\"You are an experienced SpringBoot architect adhering to devonfw standards.\n",
    "      Based on requirements for an entity, you determine if any files need to be created inside the common folder (e.g. enums).\n",
    "    \"\"\"\n",
    "    message = f\"\"\"These are the requirements for the entity {entity_name}: {entity_req}\n",
    "            Do the Requirements suggest that we need to create any enum files in the common folder for this Entity?\n",
    "             If yes, list them inside << >> like this: <<filenames>> and provide a short description of the files.\n",
    "             Naming convention: The filenames should ALWAYS have the Entity name: {entity_name} as a prefix.\n",
    "             Make sure the filenames are separated by a comma and a space and end with .java.\n",
    "\n",
    "             If no additional files are needed, reply \"No additional files needed for this entity.\"\n",
    "\n",
    "             If files are needed, structure your reply like this:\n",
    "             Structure your reply like this: \n",
    "             <<filenames>>\n",
    "             ####file: description of file.####\n",
    "             ####file: description of file.####\n",
    "             ...\n",
    "             \"\"\"\n",
    "    \n",
    "    return system_message, message\n",
    "\n",
    "def get_review_sys_message():\n",
    "\n",
    "    review_structure = open(\"review_blueprint.md\", \"r\").read()\n",
    "    system_message = f\"\"\"\n",
    "    You are a code reviewer that makes sure requirements and conventions are implemented as desired.\n",
    "    You ALWAYS reply with a review according to the structure: {review_structure}\n",
    "    \"\"\"\n",
    "    return system_message\n",
    "\n",
    "def get_create_enum_message(completion, common_path, package_name_new):\n",
    "    \n",
    "    message = f\"\"\"Implement this description of files:\n",
    "                                  {completion} exactly as described, in the {common_path} folder using the respective function. \n",
    "                                  The package names are {package_name_new}, make sure to include them in your files. \n",
    "                                  Also make sure to use public enum when createing an enum.\n",
    "                                   After you implemented all files, reply \"TERMINATE\". \"\"\"\n",
    "    \n",
    "    return message\n",
    "\n",
    "def get_review_message(file_name, requirements, implementation):\n",
    "\n",
    "    entity_name = get_entity_name()\n",
    "\n",
    "    message = f\"\"\"\n",
    "    We are currently working on the entity: {entity_name}.\n",
    "    Therefore we created the file {file_name}.\n",
    "    Does this implementation <begin implementation> {implementation} <end implementation>\n",
    "    meet ALL of the requirements: {requirements}?\n",
    "    \"\"\"\n",
    "\n",
    "    return message\n",
    "\n",
    "def get_redo_message(file_name, entity_req, file_path, review_report):\n",
    "\n",
    "    entity_name = get_entity_name()\n",
    "    implementation = read_file(file_path)\n",
    "\n",
    "    entity_redo = f\"\"\"\n",
    "    We are currently working on the entity: {entity_name}.\n",
    "    Therefore we created the file {file_name}.\n",
    "    These were the requirements for the file: {entity_req}. \n",
    "    This is the current implementation: {implementation}.\n",
    "    The implementation is flawed, as this review report suggests: {review_report}. \n",
    "    Please redo the implementation according to the requirements and the review report.\n",
    "    Use the according function and insert your codeat {file_path}\n",
    "    \"\"\"\n",
    "\n",
    "    return entity_redo\n",
    "\n",
    "def get_entity_message(full_entity_path, entity_req, package_name, enums):\n",
    "\n",
    "    message = f\"\"\"The path to the entity file is {full_entity_path} and the requirements are {entity_req}.\n",
    "        The package name will be {package_name}.\n",
    "        Implement the entity according to the requirements and the package name. Make sure to import all packages that you refer to in your code.\n",
    "        {enums} \n",
    "        \"\"\"\n",
    "    return message\n",
    "\n",
    "def get_dto_message(entity_impl, package_name, file_name, path, enums_message):\n",
    "    entity_name = get_entity_name()\n",
    "    message = f\"\"\"Implement the DTO for the entity according to following implementation of the entity: {entity_impl} file. The package name will be {package_name} and the filename will be {file_name}.\n",
    "                                Create the file at {path}.{enums_message}. Also make sure to import lombok and annotate the Dto with @Getter and @Setter.\n",
    "                                Do not forget to import the {entity_name}.java file.\n",
    "                               \"\"\"\n",
    "    \n",
    "    return message\n",
    "\n",
    "def get_repo_query_message(entity_impl):\n",
    "    entity_name = get_entity_name()\n",
    "    entity_req = get_entity_requirements()\n",
    "\n",
    "    message = f\"\"\"Based on the requirements for the entity {entity_name} and the current implementation, suggest queries that can be used to retrieve data from the database.\n",
    "    Keep in mind that JPA methods like findAll exist, so do not make unnecessary suggestions.\n",
    "      The requirements for the entity are:\n",
    "      {entity_req} The current implementation of the entity is: {entity_impl}\"\"\"\n",
    "\n",
    "    sys_message = \"You are a springboot architect that suggests repository queries.\"\n",
    "    return sys_message, message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Launch_component_workflow\n",
    "2. Launch_entity_workflow\n",
    "3. Launch_Repository workflow\n",
    "4. Launch_testing_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_human(question: Annotated[str, \"Question to be asked to the human agent\"]) -> Annotated[str, \"Answer\"]:\n",
    "  answer = input(f\"\"\"Please answer the question: {question}\\n\"\"\")\n",
    "  if answer == \"TERMINATE\":\n",
    "      sys.exit()\n",
    "\n",
    "\n",
    "  return answer\n",
    "\n",
    "def get_usage(res):\n",
    "    prompt_tokens_used = res.usage.prompt_tokens\n",
    "    completion_tokens_used = res.usage.completion_tokens\n",
    "    cost = prompt_tokens_used*(10.00 / 1e6) + completion_tokens_used*(30.00 / 1e6)\n",
    "    print(\"prompt tokens used: \", prompt_tokens_used)\n",
    "    print(\"completion tokens used: \", completion_tokens_used)\n",
    "    print(f\"\"\"Cost: {cost} USD for GPT-4\"\"\")\n",
    "\n",
    "    return\n",
    "\n",
    "def get_openai_reply(system_message, message):\n",
    "\n",
    "    client = OpenAI()\n",
    "    if type(message)== str:\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        messages = message\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages= messages, \n",
    "        temperature=0.2\n",
    "    )\n",
    "    completion = res.choices[0].message.content\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": completion})\n",
    "\n",
    "    get_usage(res)\n",
    "\n",
    "    return completion, messages\n",
    "\n",
    "def analyze_human_input(human_input, messages):\n",
    "\n",
    "    task = f\"\"\" Your boss reviewed your answer and wrote some feedback.\n",
    "      Please provide a new answer, following exactly the previous structure, but with the new input from your boss in mind. What he says is LAW. This is the feedback: {human_input}\"\"\"\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": task})\n",
    "\n",
    "    completion, new_messages = get_openai_reply(\"x\", messages)\n",
    "    return completion, new_messages\n",
    "\n",
    "def get_special_files_sugg():\n",
    "    system_message, message = get_special_files_message()\n",
    "    completion, messages = get_openai_reply(system_message, message)\n",
    "    return completion, messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_agent_usage(assistant_name, proxy_name):\n",
    "\n",
    "    print(\"Usage  \",proxy_name.name, \": \", coder_proxy.print_usage_summary())\n",
    "    print(\"Usage  \",assistant_name.name, \": \", assistant_name.print_usage_summary())\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def get_path():\n",
    "    tree = list_directories()\n",
    "    client = OpenAI()\n",
    "    res = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant. You are helping a user to navigate to a specific directory in a SpringBoot project.  \"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"This is the structure of my current directory: {tree}\n",
    "                Based on this structure, infer the path to the Spring Boot project directory, where a business component would be created inside the Spring Boot project It is usually the same directory where the Application file is located. Enclose the path in special markers like so: <<file_path>>. The path to the directory is:\"\"\"},\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    completion = res.choices[0].message.content\n",
    "    \n",
    "    # parse the path from the completion, it is wrapped in << >>\n",
    "    completion = completion.split(\"<<\")[1].split(\">>\")[0]\n",
    "    # write path to file for global storage\n",
    "    with open('spring_project_path.txt', 'w') as f:\n",
    "        f.write(completion)\n",
    "\n",
    "    \n",
    "\n",
    "    return f\"\"\" The path {completion} has been written to the file spring_project_path.txt\"\"\"\n",
    "\n",
    "def get_package_name(location_of_file):\n",
    "    # if com in path, remove everything before it\n",
    "    if f\"\"\"\\\\com\\\\\"\"\" in location_of_file:\n",
    "        package_name = location_of_file[location_of_file.find(f\"\"\"\\\\com\\\\\"\"\"):]\n",
    "        # remove last part of path\n",
    "        package_name = package_name[:location_of_file.rfind(f\"\"\"\\\\\"\"\")]\n",
    "\n",
    "        package_name = package_name.replace(f\"\"\"\\\\\"\"\", \".\")\n",
    "        if package_name.startswith(\".\"):\n",
    "            package_name = package_name[1:] \n",
    "\n",
    "    else: \n",
    "        package_name = ask_human(\"Please provide the package name for the entity.\")\n",
    "\n",
    "    return package_name\n",
    "\n",
    "def suggest_queries(entity_path):\n",
    "\n",
    "    # get implementation of entity\n",
    "    entity_impl = read_file(entity_path)\n",
    "\n",
    "    system_message, message = get_repo_query_message(entity_impl)\n",
    "\n",
    "    completion, messages = get_openai_reply(system_message, message)\n",
    "    print(\"+++++suggested queries+++++\")\n",
    "    print(completion)\n",
    "    \n",
    "    feedback = ask_human(\"Please review the suggestions and give feedback. If everything looks fine, press enter.\")\n",
    "    \n",
    "    # Loop for refinements based on feedback\n",
    "    while feedback:\n",
    "\n",
    "        completion = analyze_human_input(feedback, messages)[0]\n",
    "        print(\"+++++suggested new queries+++++\")\n",
    "        print(completion)\n",
    "        feedback = ask_human(\"Please review the suggestions and give feedback. If everything looks fine, press enter.\")\n",
    "\n",
    "    return completion\n",
    "          \n",
    "\n",
    "\n",
    "def document_entity():\n",
    "    pass\n",
    "\n",
    "def append_file_to_entity_files(name_of_file):\n",
    "    # get current list of files\n",
    "    with open(\"./entity_files.py\", 'r') as file:\n",
    "        files = file.read()\n",
    "    \n",
    "    if files:\n",
    "        list(files).append(name_of_file)\n",
    "    else:\n",
    "        files = [name_of_file]\n",
    "\n",
    "    with open(\"./entity_files.py\", 'w') as file:\n",
    "        file.write(str(files))\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_req_ent(package_name, enums):\n",
    "    # entity requirements general (lombok, jakarta.persistence)\n",
    "    # special requirements: uses the following enums:...\n",
    "    entity_req = get_entity_requirements()\n",
    "    \n",
    "    entity_req_message = f\"\"\"\n",
    "    Devon guidelines: \n",
    "    A JPA/Hibernate Java entity shall be designed, with @Entity, and optionally @Table for naming. Use @Column for mapping attributes to columns; ensure a no-argument constructor,\n",
    "    non-final classes/methods for Hibernate. Table names should always be singuar. Utilize standard Java types, custom types via AttributeConverter or @Embeddable. For Enums, use @Enumerated(EnumType.STRING);\n",
    "    large objects with @Lob, considering streaming for BLOBs. Handle dates with @Temporal. Define relationships with @ManyToOne, @OneToMany, @ManyToMany (lazy by default), \n",
    "    @OneToOne (set to lazy), avoid bidirectional complexities, use Sets for collections, and Long with @GeneratedValue for primary keys. Implement embeddables with @Embeddable, \n",
    "    choose @Inheritance strategy, typically SINGLE_TABLE. Entities should be simple, database-structure focused, avoiding business logic. Use Lombok for auto-generating getters/setters,\n",
    "    with @Getter and @Setter annotation.\n",
    "\n",
    "    The requirements for the entity are: {entity_req}\n",
    "    And the file should implement the package {package_name} and use the enums, which were already created: {enums}\n",
    "    \"\"\"\n",
    "\n",
    "    return entity_req_message\n",
    "\n",
    "def get_req_enum(num_enum, package_name):\n",
    "    # requirements for enums: stored in a file\n",
    "    enum_reqs = open(\"enum_files.txt\", \"r\").read()\n",
    "\n",
    "    # Adjusting the split logic to properly separate entries\n",
    "    sections = enum_reqs.split('<<')[1:]  # Skip the first empty entry if any\n",
    "\n",
    "    # Validate the requested enum number\n",
    "    if num_enum < 0 or num_enum >= len(sections):\n",
    "        return \"Invalid number for file and description in get_req_enum\"\n",
    "    \n",
    "    # Extract the filename and description with an adjusted regex pattern\n",
    "    pattern = r'(.*?)>>\\s*####(.*?): (.*?)####'\n",
    "    match = re.search(pattern, sections[num_enum], re.DOTALL)\n",
    "    if match:\n",
    "        filename = match.group(1).strip()\n",
    "        description = match.group(3).strip()\n",
    "        enum_req = filename + \": \" + description\n",
    "        \n",
    "        enum_req_message = f\"\"\"\n",
    "        The enum will be used by the entity and will implement the following requirements: {enum_req}\n",
    "        Inside the package {package_name}\n",
    "        \"\"\"\n",
    "        return enum_req_message\n",
    "    else:\n",
    "        return \"Error in parsing file and description\"\n",
    " \n",
    "def get_req_dto(entity_impl, package_name, enums_message):\n",
    "    entity_name = get_entity_name()\n",
    "    f\"\"\"The DTO for the entity {entity_name} should be implemented according to following implementation of the entity: {entity_impl} file. The package name should be {package_name}.\n",
    "                                {enums_message}. Also make sure to import lombok and annotate the Dto with @Getter and @Setter.\n",
    "                                Also the implementation should strictly adhere to Java naming conventions and Devon guidelines.\n",
    "                               \"\"\"\n",
    "\n",
    "def get_req_repo(package_name, suggestions):\n",
    "    entity_name = get_entity_name()[1]\n",
    "    repo_req = f\"\"\"\n",
    "    The requirements for the repository are: {suggestions}\n",
    "    The repository should implement the package {package_name} for the Entity {entity_name}\n",
    "    The repository should be created with the name {entity_name}Repository extending JpaRepository.\n",
    "    \"\"\"\n",
    "    return repo_req\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_request_workflow():\n",
    "    pass\n",
    "\n",
    "def launch_review_workflow(file_path, requirements, file_name):\n",
    "  \n",
    "    implementation = read_file(file_path)\n",
    "\n",
    "    system_message = get_review_sys_message()\n",
    "    review_message = get_review_message(file_name, requirements, implementation)\n",
    "    review, messages = get_openai_reply(system_message, review_message)   \n",
    "     \n",
    "    print(\"+++++++++++++++ FIRST REVIEW +++++++++++++++ \\n\")\n",
    "    logging.info(review)\n",
    "    # launch loop for rework\n",
    "    while \"Needs rework: Yes\" in review:\n",
    "        \n",
    "        print(\"++++++++++++++entering rework loop+++++++++++++\")\n",
    "        # ask for feedback\n",
    "        feedback = ask_human(human_question)\n",
    "\n",
    "        if feedback:\n",
    "            review, messages = analyze_human_input(feedback, messages)\n",
    "\n",
    "            print(\"++++++++++++++REWORKED REVIEW+++++++++++++\\n \")\n",
    "            logging.info(review)\n",
    "            if \"Needs rework: No\" in review:\n",
    "                break\n",
    "\n",
    "        redo_proxy.initiate_chat(redo_coder, message = get_redo_message(file_name, requirements, file_path, review))\n",
    "        implementation = read_file(file_path)\n",
    "        \n",
    "        review_message = get_review_message(file_name, requirements, implementation)\n",
    "        review, messages = get_openai_reply(system_message, review_message)  \n",
    "        logging.info(review)\n",
    "                \n",
    "    \n",
    "    return \"++++++++++++++++Review of special files complete.+++++++++++++++++\"\n",
    "\n",
    "def launch_testing_workflow():\n",
    "    pass\n",
    "\n",
    "def launch_repository_workflow(entity_path, package_name):\n",
    "\n",
    "    # get entity name from the path\n",
    "    entity_name = get_entity_name()\n",
    "\n",
    "    # infer useful queries from the entity requirements and implementation\n",
    "    suggestions = suggest_queries(entity_path)\n",
    "    # remove entity from path to get the path to the repository\n",
    "    repo_path = entity_path[:entity_path.rfind(\"\\\\\")] + \"\\\\repository\"\n",
    "    package_name = package_name + \"repository\"\n",
    "    file_name = entity_name + \"Repository.java\"\n",
    "    # launch the repository coder\n",
    "    repo_proxy.initiate_chat(repo_coder, message=f\"\"\"The current implementation of the entity is:\n",
    "                              {read_file(entity_path)}. Create the repository file for the entity {entity_name} in the package {package_name} At the location {repo_path} under the name {file_name}.\n",
    "                              Implement the suggested queries: {suggestions}. And don´t forget to import the entity from {entity_path}.\"\"\")\n",
    "\n",
    "    # get usage summary of the agents\n",
    "    get_agent_usage(repo_coder, repo_proxy)\n",
    "\n",
    "    # append the file to the list of entity files\n",
    "    #append_file_to_entity_files(file_name)\n",
    "\n",
    "    # initiate review workflow  \n",
    "    repo_req = get_req_repo(package_name, suggestions)\n",
    "\n",
    "    print(\"starting Repository review workflow \")\n",
    "    launch_review_workflow(repo_path + \"\\\\\" + file_name, repo_req, file_name)\n",
    "\n",
    "\n",
    "    return entity_name, \"Repository has been created.\"\n",
    "\n",
    "def launch_dto_workflow(entity_path, common_path, package_name, enums):\n",
    "\n",
    "    entity_name = get_entity_name()\n",
    "    if enums == \"No additional files are needed\":\n",
    "        enums = \"\"\n",
    "    else:\n",
    "        enums_message = f\"\"\" The files {enums} have been created in the common folder, import them in your implementation from {common_path}\"\"\"\n",
    "        \n",
    "\n",
    "    # read the entity file\n",
    "    entity_impl = read_file(entity_path)\n",
    "\n",
    "    # create package name for the dto by removing the last part of the package name and adding .common.to\n",
    "    package_name = package_name[:package_name.rfind(\".\")] + \".common.to\"\n",
    "    path = common_path + \"\\\\to\"\n",
    "\n",
    "    file_name = entity_name + \"Dto.java\"\n",
    "\n",
    "    message = get_dto_message(entity_impl, package_name,file_name, path, enums_message)\n",
    "    # launch the dto coder\n",
    "    coder_proxy.initiate_chat(coder,message = message)\n",
    "\n",
    "    get_agent_usage(coder, coder_proxy)\n",
    "\n",
    "    # review workflow\n",
    "    entity_req = get_req_dto(entity_impl, package_name, enums_message)\n",
    "\n",
    "    print(\"+++++++++++++++++++starting DTO review workflow++++++++++++++++++++\")\n",
    "    launch_review_workflow(path + \"\\\\\" + file_name, entity_req, file_name)\n",
    "\n",
    "\n",
    "    # append the file to the list of entity files\n",
    "    append_file_to_entity_files(file_name)\n",
    "    return \"DTO has been created.\"\n",
    "\n",
    "def launch_entity_impl_worlflow(full_entity_path, entity_req, package_name, enums, entity_name):\n",
    "\n",
    "    message = get_entity_message(full_entity_path, entity_req, package_name, enums) \n",
    "\n",
    "    entity_proxy.initiate_chat(entity_coder, message= message)\n",
    "    \n",
    "    # print usage summary of the agents\n",
    "    get_agent_usage(entity_coder, entity_proxy)\n",
    "\n",
    "    append_file_to_entity_files(entity_name+\".java\")\n",
    "\n",
    "    # initiate review workflow\n",
    "    entity_req = get_req_ent(package_name, enums)\n",
    "\n",
    "    print(\"+++++++++++++++++++starting Entity review workflow for: \", entity_name, \"++++++++++++++++++++\")\n",
    "    launch_review_workflow(full_entity_path, entity_req, entity_name)\n",
    "\n",
    "\n",
    "    return f\"\"\"+++++++++++++++Entity file for {entity_name} has been created. Proceed with DTO workflow.+++++++++++\"\"\"\n",
    "\n",
    "def create_enums(completion, list_of_files, common_path):\n",
    "\n",
    "        package_name = get_package_name(common_path)\n",
    "        # create the files in the common folder\n",
    "        coder_proxy.initiate_chat(coder, message = get_create_enum_message(completion, common_path, package_name))\n",
    "        # print the usage summary of the agents\n",
    "        get_agent_usage(coder, coder_proxy)\n",
    "\n",
    "        # store the completion in a file for later reference\n",
    "        with open('enum_files.txt', 'w') as f:\n",
    "            f.write(completion+ \"The package name for all files is: \" + package_name + \" . The path to the common folder is: \" + common_path)\n",
    "\n",
    "        # write the list of files to a file for later reference\n",
    "        with open('entity_files.py', 'w') as f:\n",
    "            f.write(\"files = \"+ str(list_of_files))\n",
    "\n",
    "\n",
    "def special_files(common_path):\n",
    "    \n",
    "    package_name = get_package_name(common_path)\n",
    "    completion, messages = get_special_files_sugg()\n",
    "    logging.info(f\"Suggestion: {completion}\")\n",
    "    # ask human if the suggestion is correct\n",
    "    human_input = ask_human(f\"\"\"The AI suggests: {completion} Is this correct? If yes hit enter, if no, please provide the correct description using \"<<filenames>>\" for the filenames.\"\"\")\n",
    "\n",
    "    if human_input:\n",
    "        completion = analyze_human_input(human_input, messages)[0]\n",
    "\n",
    "    # if list of files is not empty\n",
    "    if \"<<\" in completion:\n",
    "        # get the list of files from the completion\n",
    "        list_of_files = completion.split(\"<<\")[1].split(\">>\")[0].split(\", \")   \n",
    "\n",
    "        print(\"The following list of files will be created:\", list_of_files)\n",
    "\n",
    "        create_enums(completion, list_of_files, common_path)\n",
    "\n",
    "        for i in range(0, len(list_of_files)):\n",
    "            req = get_req_enum(i, package_name)\n",
    "            path = common_path + \"\\\\\" + list_of_files[i]\n",
    "  \n",
    "            print(\"starting enum review workflow for: \", list_of_files[i])\n",
    "            launch_review_workflow(path, req, list_of_files[i])\n",
    "\n",
    "        if len(list_of_files) > 1:\n",
    "            enums = f\"\"\"The following files have been created for the entity. Import them in your implementation from {common_path} + filename(s): {list_of_files}\"\"\"\n",
    "        else:\n",
    "            enums = f\"\"\"The following file has been created for the entity. Import it in your implementation from {common_path} + filename: {list_of_files}\"\"\"\n",
    "\n",
    "\n",
    "    else: \n",
    "        # create empty entity_files.py file, overwriting the old one if exists\n",
    "        with open('entity_files.py', 'w') as f:\n",
    "            f.write(\"files = []\")\n",
    "\n",
    "        enums = \"\"\n",
    "\n",
    "    return enums\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_entity_workflow(component_name):\n",
    "    \n",
    "    # get path to spring project\n",
    "    spring_path = open('spring_project_path.txt', 'r').read()    \n",
    "\n",
    "    # get the path to the common folder\n",
    "    common_path = os.path.join(spring_path, component_name, \"common\")\n",
    "\n",
    "    # replace forward with back slashes\n",
    "    common_path = common_path.replace(\"/\", \"\\\\\")\n",
    "\n",
    "    while True:\n",
    "        entity_name = get_entity_name()\n",
    "        if entity_name == \"All entities are implemented, component has been marked as done. TERMINATE\":\n",
    "            return entity_name\n",
    "\n",
    "        else:\n",
    "\n",
    "            entity_path = os.path.join(spring_path, component_name, 'dataaccess', f'{entity_name}.java').replace(\"/\", \"\\\\\")\n",
    "\n",
    "            ##### check if any special requests exist (flexibility to be implemented######\n",
    "            package_name = get_package_name(entity_path)\n",
    "            # get the entity requirements\n",
    "            entity_req = get_entity_requirements()\n",
    "            \n",
    "            print(\"++++++++++++++++starting special file workflow+++++++++++++++\")\n",
    "            enums = special_files(common_path) \n",
    "        \n",
    "            print(\"+++++++++++++++++starting entity implementation workflow++++++++++++++\")\n",
    "            launch_entity_impl_worlflow(entity_path, entity_req, package_name, enums, entity_name)\n",
    "\n",
    "            print(\"+++++++++++++++++starting DTO workflow++++++++++++++++++++\")\n",
    "            launch_dto_workflow(entity_path, common_path, package_name, enums)\n",
    "\n",
    "            print(\"++++++++++++++++++starting repository workflow++++++++++++++++++\")\n",
    "            launch_repository_workflow(entity_path, package_name)\n",
    "\n",
    "            print(\"++++++++++++++++++ENTITY DONE++++++++++++++++++++\")\n",
    "            mark_next_entity_done()\n",
    "\n",
    "            print(\"++++++++++++++++++STARTING\", entity_name, \"++++++++++++++++++\")\n",
    "\n",
    "def launch_component_workflow():\n",
    "    try:\n",
    "\n",
    "        # get the path to the spring project and store it once\n",
    "        get_path()\n",
    "\n",
    "        # loop through the components\n",
    "        while True:\n",
    "\n",
    "            component_name = get_component_name()\n",
    "            \n",
    "            if component_name == \"All components are implemented. TERMINATE\":\n",
    "                return component_name\n",
    "            \n",
    "            else:\n",
    "                # ask clarifying questions\n",
    "                clarifying_question =\"I will create the component structure according to the devon guidelines. If you have a special request, let me know, otherwise press enter to proceed.\"\n",
    "                answer = ask_human(clarifying_question)\n",
    "                if answer:\n",
    "                    special_request_workflow()\n",
    "\n",
    "                else:\n",
    "                    result = create_component_structure(open('spring_project_path.txt', 'r').read())\n",
    "                    while \"does not exist\" in result:\n",
    "                        print(result)  # Inform the user of the issue.\n",
    "                        get_path()  # Obtain a new path.\n",
    "                        result = create_component_structure(open('spring_project_path.txt', 'r').read())  # Retry with the new path.\n",
    "                    \n",
    "                    # If this point is reached, the component was created successfully.\n",
    "                    print(result)\n",
    "\n",
    "\n",
    "\n",
    "                launch_entity_workflow(component_name = component_name)\n",
    "\n",
    "    except SystemExit:\n",
    "        print(\"Program terminated by user.\")\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folders and files for CourseManagement have been created. The [Entity].java files are located in ..\\Gabis-MVP SpringBoot\\src\\main\\java\\com\\gabismvp\\coursemanagement/dataaccess.\n",
      "++++++++++++++++starting special file workflow+++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Suggestion: <<CourseLevel.java>>\n",
      "####file: This file would define an enum for the Course Level attribute, which includes the values Beginner, Intermediate, and Advanced.####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt tokens used:  409\n",
      "completion tokens used:  32\n",
      "Cost: 0.005050000000000001 USD for GPT-4\n",
      "The following list of files will be created: ['CourseLevel.java']\n",
      "\u001b[33mcoder_proxy\u001b[0m (to coder):\n",
      "\n",
      "Implement this description of files:\n",
      "                                  <<CourseLevel.java>>\n",
      "####file: This file would define an enum for the Course Level attribute, which includes the values Beginner, Intermediate, and Advanced.#### exactly as described, in the src\\main\\java\\com\\gabismvp\\coursemanagement\\common folder using the respective function. \n",
      "                                  The package names are com.gabismvp.coursemanagement.common, make sure to include them in your files. \n",
      "                                  Also make sure to use public enum when createing an enum.\n",
      "                                   After you implemented all files, reply \"TERMINATE\". \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcoder\u001b[0m (to coder_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested tool Call (call_PPQEnS9pC49etGKMbzCqDPGR): write_file *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"file_path\": \"src\\\\main\\\\java\\\\com\\\\gabismvp\\\\coursemanagement\\\\common\\\\CourseLevel.java\",\n",
      "  \"content\": \"package com.gabismvp.coursemanagement.common;\\n\\npublic enum CourseLevel {\\n    BEGINNER,\\n    INTERMEDIATE,\\n    ADVANCED\\n}\"\n",
      "}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION write_file...\u001b[0m\n",
      "\u001b[33mcoder_proxy\u001b[0m (to coder):\n",
      "\n",
      "\u001b[33mcoder_proxy\u001b[0m (to coder):\n",
      "\n",
      "\u001b[32m***** Response from calling tool \"call_PPQEnS9pC49etGKMbzCqDPGR\" *****\u001b[0m\n",
      "Content successfully written to ..\\Gabis-MVP SpringBoot\\src\\main\\java\\com\\gabismvp\\coursemanagement\\common\\CourseLevel.java\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcoder\u001b[0m (to coder_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "No cost incurred from agent 'coder_proxy'.\n",
      "Usage   coder_proxy :  None\n",
      "Agent 'coder':\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Usage summary excluding cached usage: \n",
      "Total cost: 0.04745\n",
      "* Model 'gpt-4-1106-preview': cost: 0.04745, prompt_tokens: 3821, completion_tokens: 308, total_tokens: 4129\n",
      "\n",
      "All completions are non-cached: the total cost with cached completions is the same as actual cost.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Usage   coder :  None\n",
      "starting enum review workflow for:  CourseLevel.java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:# Code Review for CourseLevel.java\n",
      "Needs rework: Yes\n",
      "\n",
      "## Functionality\n",
      "\n",
      "### Syntax or logic errors\n",
      "None\n",
      "\n",
      "### Adherence to requirements\n",
      "\n",
      "All requirements met: No\n",
      "\n",
      "Description of problems:\n",
      "- The enum values are in uppercase, whereas the requirements specify that the values should be \"Beginner\", \"Intermediate\", and \"Advanced\" with only the first letter capitalized.\n",
      "\n",
      "Suggested Improvements:\n",
      "- Change the enum values to have only the first letter capitalized as per the requirements. The enum should look like this:\n",
      "\n",
      "```java\n",
      "public enum CourseLevel {\n",
      "    Beginner,\n",
      "    Intermediate,\n",
      "    Advanced\n",
      "}\n",
      "```\n",
      "\n",
      "### Naming Conventions\n",
      "Java naming conventions met according to devon guidelines: Yes\n",
      "\n",
      "Java enums typically have constants in all uppercase letters, which is a common practice. However, since the specific requirement is to have the values with only the first letter capitalized, the naming convention should follow the requirement in this case.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt tokens used:  258\n",
      "completion tokens used:  188\n",
      "Cost: 0.00822 USD for GPT-4\n",
      "+++++++++++++++ FIRST REVIEW +++++++++++++++ \n",
      "\n",
      "++++++++++++++entering rework loop+++++++++++++\n",
      "Program terminated by user.\n"
     ]
    }
   ],
   "source": [
    "launch_component_workflow()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
